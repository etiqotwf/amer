import * as tf from '@tensorflow/tfjs';
import fs from 'fs';
import readline from 'readline';

const MODEL_FILE = 'model.json';
const WEIGHTS_FILE = 'weights.bin';
const NORMALIZATION_FILE = 'normalization.json';
const REINFORCEMENT_FILE = 'reinforcement.json';
const BACKUP_FILE = "reinforcement.json.backup";
const TEMP_FILE = "reinforcement.json.tmp";
import path from 'path';
import os from 'os';
const USD_TO_EGP = 50.67;
const LEARNING_RATE = 0.01;
const EPOCHS = 100;
const DISCOUNT_FACTOR = 0.95;
const EPSILON = 0.1;
const REPLAY_BUFFER_SIZE = 100;


// Function to reset all files
function resetFiles() {
    const files = [REINFORCEMENT_FILE, WEIGHTS_FILE, MODEL_FILE, NORMALIZATION_FILE];

    files.forEach(file => {
        if (fs.existsSync(file)) {
            fs.unlinkSync(file);
            console.log(`âœ… Deleted: ${file}`);
        } else {
            console.log(`âš ï¸ Not found: ${file}`);
        }
    });

    console.log("ğŸš€ All files have been reset.");
}

// Check if the script was run with "reset" argument
if (process.argv[2] === 'reset') {
    resetFiles();
    process.exit(); // Exit after resetting files
}


// Function to save and download the backup file
function saveBackup() {
    if (!fs.existsSync(BACKUP_FILE)) {
        console.log("âŒ Backup file not found!");
        return;
    }

    // Get the user's Downloads folder
    const downloadsFolder = path.join(os.homedir(), 'Downloads');
    const destinationPath = path.join(downloadsFolder, BACKUP_FILE);

    // Copy the backup file to Downloads
    fs.copyFileSync(BACKUP_FILE, destinationPath);
    console.log(`âœ… Backup file saved to: ${destinationPath}`);
}

// Check command-line arguments
const command = process.argv[2];

if (command === 'reset') {
    resetFiles();
    process.exit();
} else if (command === 'save') {
    saveBackup();
    process.exit();
}





// âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¶Ù…Ø§Ù† Ø£Ù†Ù‡Ø§ Ù…ØµÙÙˆÙØ©
let replayBuffer = [];

try {
    if (fs.existsSync(REINFORCEMENT_FILE)) {
        const data = fs.readFileSync(REINFORCEMENT_FILE, 'utf-8').trim();
        const parsedData = data ? JSON.parse(data) : [];

        // ğŸ”¹ If the data is an array, assign it; otherwise, keep the existing data
        if (Array.isArray(parsedData)) {
            replayBuffer = parsedData;
        } else {
            console.warn("âš ï¸ Warning: The replay file contains invalid data. Keeping the current buffer.");
        }
    } else {
        console.warn("âš ï¸ Warning: The replay file does not exist. Continuing with the current buffer.");
    }
} catch (error) {
    console.error("âŒ Error: Unable to read the replay file.", error);
    console.warn("âš ï¸ Continuing with the existing buffer in memory.");
}


// âœ… Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§
function modelExists() {
    const files = [MODEL_FILE, WEIGHTS_FILE, NORMALIZATION_FILE, REINFORCEMENT_FILE];

    for (let file of files) {
        if (!fs.existsSync(file) || fs.statSync(file).size === 0) {
            return false;
        }
    }
    return true;
}

// âœ… ÙˆØ¸ÙŠÙØ© Ù„Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ù…Ø¹Ø²Ø² Ø¨Ø¹Ø¯ ÙƒÙ„ ØªØ­Ø¯ÙŠØ«
function storeExperience(state, actualCost) {
    if (state == null || actualCost == null) {
        console.warn("âš ï¸ Warning: Invalid experience data received.");
        return;
    }

    // ğŸ”¹ ØªØ£ÙƒÙŠØ¯ Ø£Ù† replayBuffer Ù…ØµÙÙˆÙØ©
    if (!Array.isArray(replayBuffer)) {
        console.warn("âš ï¸ replayBuffer was not an array. Resetting...");
        replayBuffer = [];
    }

    replayBuffer.push({ state, actualCost });

    if (replayBuffer.length > REPLAY_BUFFER_SIZE) {
        replayBuffer.splice(0, 1);
    }

    try {
        fs.writeFileSync(REINFORCEMENT_FILE, JSON.stringify(replayBuffer, null, 2));
        console.log(`ğŸ“¦ Data stored successfully. Current size: ${replayBuffer.length}`);
    } catch (error) {
        console.error("âŒ Error saving reinforcement learning data:", error);
    }
    
}



function createModel() {
    const model = tf.sequential();
    model.add(tf.layers.dense({ units: 64, activation: 'relu', inputShape: [8] }));
    model.add(tf.layers.dense({ units: 32, activation: 'relu' }));
    model.add(tf.layers.dense({ units: 1 }));
    model.compile({ optimizer: tf.train.adam(LEARNING_RATE), loss: 'meanSquaredError' });
    return model;
}




async function saveModel(model, normalizationParams, reinforcementData) {
    await model.save(tf.io.withSaveHandler(async (artifacts) => {
        fs.writeFileSync(MODEL_FILE, JSON.stringify({
            modelTopology: artifacts.modelTopology,
            weightSpecs: artifacts.weightSpecs
        }));
        fs.writeFileSync(WEIGHTS_FILE, Buffer.from(artifacts.weightData));
        fs.writeFileSync(NORMALIZATION_FILE, JSON.stringify(normalizationParams, null, 2));

        // Protect Replay Buffer data
        const TEMP_FILE = `${REINFORCEMENT_FILE}.tmp`;
        const BACKUP_FILE = `${REINFORCEMENT_FILE}.backup`;

        try {
            if (!Array.isArray(reinforcementData)) {
                console.warn("âš ï¸ Invalid reinforcement data! Skipping save.");
                return;
            }

            let existingData = [];

            // Load existing reinforcement data if available
            if (fs.existsSync(REINFORCEMENT_FILE)) {
                try {
                    const fileContent = fs.readFileSync(REINFORCEMENT_FILE, 'utf-8').trim();
                    if (fileContent.length > 0) {
                        existingData = JSON.parse(fileContent);
                        if (!Array.isArray(existingData)) {
                            console.warn("âš ï¸ Existing reinforcement file is not an array. Resetting...");
                            existingData = [];
                        }
                    }
                } catch (e) {
                    console.error("âŒ Error reading existing reinforcement data:", e);
                    existingData = [];
                }
            }

            // Append new data to the existing array
            const updatedData = existingData.concat(reinforcementData);

            // Create a backup only if the file contains valid data
            if (existingData.length > 0) {
                fs.copyFileSync(REINFORCEMENT_FILE, BACKUP_FILE);
            }

            // Write to a temporary file first
            fs.writeFileSync(TEMP_FILE, JSON.stringify(updatedData, null, 2));

            // Replace the original file only after successful writing
            fs.renameSync(TEMP_FILE, REINFORCEMENT_FILE);

            // Validate record count after saving
            let savedData = [];
            let backupData = [];

            try {
                savedData = JSON.parse(fs.readFileSync(REINFORCEMENT_FILE, 'utf-8'));
            } catch (e) {
                console.error("âŒ Failed to read saved data:", e);
            }

            if (fs.existsSync(BACKUP_FILE)) {
                try {
                    backupData = JSON.parse(fs.readFileSync(BACKUP_FILE, 'utf-8'));
                } catch (e) {
                    console.error("âŒ Failed to read backup data:", e);
                }
            } else {
                console.warn("âš ï¸ Backup file not found, cannot validate record count.");
            }

            console.log(`ğŸ“Š Records in backup: ${backupData.length}`);

            // Restore backup only if it contains valid data
            if (backupData.length > 0 && savedData.length !== backupData.length) {
                console.warn("âš ï¸ Record count mismatch detected. Restoring from backup...");
                fs.copyFileSync(BACKUP_FILE, REINFORCEMENT_FILE);
                console.log("âœ… Reinforcement file restored from backup.");
            }

            console.log("âœ… Model, reinforcement learning data & normalization parameters saved successfully!");

// Stop execution after success
process.exit(0);

        } catch (error) {
            console.error("âŒ Error saving reinforcement data:", error);

            // Restore data only if the backup file is valid
            if (fs.existsSync(BACKUP_FILE)) {
                const backupContent = fs.readFileSync(BACKUP_FILE, 'utf-8').trim();
                if (backupContent.length > 0) {
                    fs.copyFileSync(BACKUP_FILE, REINFORCEMENT_FILE);
                    console.warn("âš ï¸ Data restored from backup due to an error.");
                } else {
                    console.warn("âš ï¸ Backup not restored because it is empty.");
                }
            }
// Exit with failure code after handling the error
process.exit(1);


        }
    }));
}




async function loadModel() {
    console.log("ğŸ“‚ Loading saved model...");

    try {
        // âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
        if (!fs.existsSync(MODEL_FILE) || !fs.existsSync(WEIGHTS_FILE)) {
            throw new Error("âŒ Model files not found!");
        }

        const modelData = JSON.parse(fs.readFileSync(MODEL_FILE, 'utf8'));
        const weightData = fs.readFileSync(WEIGHTS_FILE);
        const modelArtifacts = {
            modelTopology: modelData.modelTopology,
            weightSpecs: modelData.weightSpecs,
            weightData: new Uint8Array(weightData).buffer
        };

        // âœ… ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠØ¹
        if (!fs.existsSync(NORMALIZATION_FILE)) {
            throw new Error("âŒ Normalization file not found!");
        }
        const normalizationParams = JSON.parse(fs.readFileSync(NORMALIZATION_FILE, 'utf8'));

        // âœ… ØªØ­Ù…ÙŠÙ„ Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ… Ø§Ù„ØªØ¹Ø²ÙŠØ²ÙŠ
        let reinforcementData = {}; 
        if (fs.existsSync(REINFORCEMENT_FILE)) {
            reinforcementData = JSON.parse(fs.readFileSync(REINFORCEMENT_FILE, 'utf8'));
            console.log("ğŸ“œ Reinforcement Learning Data Loaded");

            // ğŸ”„ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù‚Ø¯ÙŠÙ…Ø© Ø£Ùˆ ØºÙŠØ± Ù…ÙƒØªÙ…Ù„Ø©
            const defaultReinforcement = {
                learningRate: 0.01,
                discountFactor: 0.99,
                explorationRate: 0.1
            };
            reinforcementData = { ...defaultReinforcement, ...reinforcementData };
            fs.writeFileSync(REINFORCEMENT_FILE, JSON.stringify(reinforcementData, null, 2));
        } else {
            console.warn("âš ï¸ Reinforcement learning file not found! Creating a new one...");
            reinforcementData = {
                learningRate: 0.01,
                discountFactor: 0.99,
                explorationRate: 0.1
            };
            fs.writeFileSync(REINFORCEMENT_FILE, JSON.stringify(reinforcementData, null, 2));
            console.log("âœ… Reinforcement learning file created successfully!");
        }

        // âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ TensorFlow.js
        const model = await tf.loadLayersModel(tf.io.fromMemory(modelArtifacts));

        // âœ… **Ø¥Ø¹Ø§Ø¯Ø© ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¹Ø¯ Ø§Ù„ØªØ­Ù…ÙŠÙ„ Ù„Ø­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©**
        model.compile({
            optimizer: tf.train.adam(),
            loss: 'meanSquaredError',
            metrics: ['mse']
        });

        console.log("âœ… Model loaded and compiled successfully!");
        return { model, normalizationParams, reinforcementData };

    } catch (error) {
        console.error("âš ï¸ Error loading model:", error.message);
        return null;
    }
}



function normalizeData(data, min, max) {
    if (!Array.isArray(data) || data.some(isNaN)) {
        throw new Error("âŒ The input data must be an array of numbers!");
    }

    return data.map((value, index) => {
        if (value < min[index]) {
            console.warn(`âš ï¸ Warning: Value at index ${index} is below the minimum (${value} < ${min[index]}). It will be set to the minimum.`);
            value = min[index];
        } else if (value > max[index]) {
            console.warn(`âš ï¸ Warning: Value at index ${index} exceeds the maximum (${value} > ${max[index]}). It will be set to the maximum.`);
            value = max[index];
        }

        return (value - min[index]) / (max[index] - min[index]);
    });
}






async function trainModel(model) {
    console.log("ğŸ—ï¸ Training the model with reinforcement learning...");

    // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Replay Buffer
    let replayBuffer = [];
    try {
        const bufferData = fs.readFileSync(REINFORCEMENT_FILE, "utf-8");
        replayBuffer = JSON.parse(bufferData);
    } catch (error) {
        console.warn("âš ï¸ No data in Replay Buffer, default data will be used.");
    }

    // Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    let rawXs = [
        [500, 1, 3, 5, 20, 1, 100, 2022],
        [1000, 2, 5, 10, 50, 2, 150, 2021],
        [700, 1, 4, 7, 30, 3, 120, 2023],
        [1200, 3, 6, 12, 60, 1, 200, 2020]
    ];

    let rawYs = [[50000], [120000], [70000], [150000]];

    replayBuffer.forEach(data => {
        if (data.state.length === 8) { // ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 8 Ù‚ÙŠÙ…
            rawXs.push(data.state);
            rawYs.push([data.actualCost]); // ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‚ÙŠÙ…Ø© Ø¥Ù„Ù‰ Ù…ØµÙÙˆÙØ©
        } else {
            console.error("âŒ Ø®Ø·Ø£: Ø¨ÙŠØ§Ù†Ø§Øª Replay Buffer ØºÙŠØ± Ù…ØªÙˆØ§ÙÙ‚Ø©", data);
        }
    });
    


// âœ… Ø·Ø¨Ø§Ø¹Ø© Ø¨ÙŠØ§Ù†Ø§Øª rawXs Ùˆ rawYs Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù‚ÙŠÙ… Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
console.log("rawXs:", rawXs);
console.log("rawYs:", rawYs);

    console.log(`ğŸ“Š Training data used: ${rawXs.length} records`);



    // ğŸ“Œ Ø­Ø³Ø§Ø¨ min Ùˆ max Ù„ÙƒÙ„ Ø¹Ù…ÙˆØ¯ ÙÙŠ rawXs
    const minInput = rawXs[0].map((_, colIndex) => Math.min(...rawXs.map(row => row[colIndex])));
    const maxInput = rawXs[0].map((_, colIndex) => Math.max(...rawXs.map(row => row[colIndex])));

    // ğŸ“Œ Ø­Ø³Ø§Ø¨ min Ùˆ max Ù„Ù€ rawYs
    const minOutput = Math.min(...rawYs.flat());
    const maxOutput = Math.max(...rawYs.flat());

    // ğŸ“Œ ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    const normalizedXs = rawXs.map(row => row.map((value, colIndex) => {
        const diff = maxInput[colIndex] - minInput[colIndex] || 1e-8;
        return (value - minInput[colIndex]) / diff;
    }));

    const normalizedYs = rawYs.map(row => row.map(value => {
        const diff = maxOutput - minOutput || 1e-8;
        return (value - minOutput) / diff;
    }));

    // ğŸ“Œ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Tensors
    const xs = tf.tensor2d(normalizedXs);
    const ys = tf.tensor2d(normalizedYs);

    try {
        console.log("ğŸš€ Training started...");
        await model.fit(xs, ys, { 
            epochs: EPOCHS, 
            batchSize: 32 // ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¬Ø±Ø¨Ø© Ù‚ÙŠÙ… Ø£Ø®Ø±Ù‰ Ù…Ø«Ù„ 16ØŒ 64ØŒ Ø­Ø³Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©
        });
        
        console.log("âœ… Training completed!");
    } catch (error) {
        console.error("âŒ Error during training:", error);
        return null;
    }

    // ğŸ“Œ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ‚ÙŠÙ… Ø§Ù„ØªØ·Ø¨ÙŠØ¹
    const normalizationParams = { minInput, maxInput, minOutput, maxOutput };

    // Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙÙ‚Ø· Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù…Ù† Replay Buffer
const reinforcementData = replayBuffer.map(data => ({
    state: data.state,
    actualCost: data.actualCost
}));

// Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ÙÙ‚Ø·
await saveModel(model, normalizationParams, reinforcementData);


    return normalizationParams;
}




async function reinforcementLearning(model, userInput, actualCost, normalizationParams) {
    if (!model || !userInput || actualCost == null || !normalizationParams) {
        console.warn("âš ï¸ Warning: Invalid input to reinforcementLearning.");
        return;
    }

    if (Math.random() < EPSILON) return;

    // ğŸ“Œ Ø­Ø³Ø§Ø¨ `newState` Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
    const newState = [...userInput]; // ÙÙ‚Ø· Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø¯ÙˆÙ† `actualCost`
    storeExperience(newState, actualCost);

    await trainModel(model);

    console.log(`ğŸ“¦ Buffer size: ${replayBuffer.length}`);

    if (replayBuffer.length < 10) return;

    // ğŸ“Œ Ø£Ø®Ø° Ø¢Ø®Ø± 50 ØªØ¬Ø±Ø¨Ø© Ø£Ùˆ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù† ÙƒØ§Ù†Øª Ø£Ù‚Ù„ Ù…Ù† 50
    const batch = replayBuffer.slice(-Math.min(50, replayBuffer.length));

    for (const { state, actualCost } of batch) {
        let inputTensor, actualTensor;

        // ğŸ“Œ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¯Ø§Ø®Ù„ `tf.tidy()`
        const tensors = tf.tidy(() => {
            const normalizedInput = normalizeData(state, normalizationParams.minInput, normalizationParams.maxInput);
            inputTensor = tf.tensor2d([normalizedInput]);
            const predictedTensor = model.predict(inputTensor);
            const predictedCost = predictedTensor.dataSync()[0];

            const reward = -Math.abs(actualCost - predictedCost);
            const targetCost = actualCost + DISCOUNT_FACTOR * reward;
            actualTensor = tf.tensor2d([[targetCost]]);

            return { inputTensor, actualTensor };
        });

        // âœ… ØªØ£ÙƒØ¯ Ù…Ù† ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚Ø¨Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        if (!model.optimizer) {
            console.log("ğŸ”„ Compiling model before training...");
            model.compile({
                optimizer: 'adam',
                loss: 'meanSquaredError'
            });
        }

        try {
            console.log("ğŸ¯ Training model...");
            await model.fit(tensors.inputTensor, tensors.actualTensor, { epochs: 50, batchSize: 5 });
            console.log("ğŸ§  Model trained!");

            await saveModel(model, normalizationParams, replayBuffer);
            console.log("âœ… Model updated and saved successfully!");
        } catch (err) {
            console.error("âŒ Training error:", err);
        } finally {
            // ğŸ”´ ØªØ­Ø±ÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙŠØ¯ÙˆÙŠÙ‹Ø§
            tensors.inputTensor.dispose();
            tensors.actualTensor.dispose();
        }
    }
}





async function askUserForInputs() {
    const rl = readline.createInterface({ input: process.stdin, output: process.stdout });
    function askQuestion(question) {
        return new Promise(resolve => rl.question(question, answer => resolve(parseFloat(answer) || 0)));
    }
    
    const questions = [
        "ğŸ“ Enter construction area (mÂ²): ",
        "ğŸ  Enter building type (1: Residential, 2: Pump Station, 3: Bridge): ",
        "ğŸ¢ Enter number of floors: ",
        "ğŸ“… Enter permit duration (years): ",
        "ğŸŒŠ Enter distance from waterway (m): ",
        "ğŸ› ï¸ Enter soil type (1: Rocky, 2: Clay, 3: Sandy): ",
        "ğŸ’° Enter material cost per mÂ²: ",
        "ğŸ“† Enter application year: "
    ];
    
    const inputs = [];
    for (const question of questions) {
        inputs.push(await askQuestion(question));
    }
    
    rl.close();
    return inputs;
}

async function askForActualCost() {
    return new Promise(resolve => {
        const rl = readline.createInterface({ input: process.stdin, output: process.stdout });
        rl.question("ğŸ’° input actualCost ", answer => {
            rl.close();
            resolve(parseFloat(answer) || 0);
        });
    });
}

async function runModel() {
    let model, normalizationParams;
    if (modelExists()) {
        ({ model, normalizationParams } = await loadModel());
    } else {
        model = createModel();
        normalizationParams = await trainModel(model);
    }
    
    const userInput = await askUserForInputs();
    if (userInput.includes(undefined) || userInput.includes(NaN)) {
        console.error("âŒ Error: Invalid user input.");
        return;
    }

    const normalizedInput = normalizeData(userInput, normalizationParams.minInput, normalizationParams.maxInput);
    if (normalizedInput.includes(NaN)) {
        console.error("âŒ Error: Normalized data contains NaN.");
        return;
    }

    const inputTensor = tf.tensor2d([normalizedInput]); 
    const predictedTensor = model.predict(inputTensor);
    const predictedCostNormalized = predictedTensor.dataSync()[0];

    if (isNaN(predictedCostNormalized)) {
        console.error("âŒ Error: Predicted cost is NaN.");
        return;
    }

    const predictedCost = predictedCostNormalized * (normalizationParams.maxOutput - normalizationParams.minOutput) + normalizationParams.minOutput;
    console.log(`ğŸ”® Predicted cost: ${predictedCost.toFixed(2)} EGP`);

    const actualCost = await askForActualCost();
    await reinforcementLearning(model, userInput, parseFloat(actualCost), normalizationParams);
}

runModel().catch(console.error);